{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "sk0A1I0Ax7lE"
      ],
      "authorship_tag": "ABX9TyMv1e8PwqJRQ5BtClNHaHtL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SolinSM/GAN/blob/main/semina2_GAN_1-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test GAN Modell"
      ],
      "metadata": {
        "id": "vE04LobhEPG2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fc2Wz5T0BzUH",
        "outputId": "ae5b263c-64b0-45e4-e95f-49921169d8ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#!pip install tensorflow==2.15.0 scikit-learn==1.2.2 keras==2.15.0   #python 3.10.12\n",
        "\n",
        "## ----- Libraries ----- ##\n",
        "#for read csv file\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "# pre-process\n",
        "##for stop word\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "## not used now\n",
        "#import unicodedata     # Remove accents\n",
        "#import string\n",
        "\n",
        "\n",
        "import sklearn\n",
        "\n",
        "## for tokenization\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import WordPunctTokenizer      ## WordPunctTokenizer --> splits words based on punctuation boundaries.\n",
        "\n",
        "## for divide data to (train / test/ validate)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# for one-hor encode (sentence to 2D)\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# for TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "\n",
        "# for plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# for GAN\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential        ## new\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input,\n",
        "    Concatenate,\n",
        "    Embedding,\n",
        "    Dense,\n",
        "    LeakyReLU,\n",
        "    BatchNormalization,\n",
        "    Dropout,\n",
        "    Reshape,\n",
        "    LSTM\n",
        ")\n",
        "\n",
        "import keras\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt         ## new\n",
        "\n",
        "import time\n",
        "# taqadum in arabic , progress/process in english\n",
        "from tqdm.notebook import tqdm\n",
        "#from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Suppress warnings from numpy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
        "\n",
        "\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# for Evaluate\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf. __version__)      # tensorflow version   2.15.0\n",
        "!python --version           # python version    3.10.12\n",
        "print(sklearn.__version__)         # scikit-learn version    1.2.2\n",
        "print(keras.__version__)           # keras version    2.15.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywujKKkDFEM2",
        "outputId": "b51e38f9-4480-4da3-b69f-85d52715f55e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n",
            "Python 3.10.12\n",
            "1.2.2\n",
            "2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ---- Color + Style Text ---- ##\n",
        "colors_list = [\n",
        "    'Red', 'Green', 'Blue', 'Purple', 'Orange', 'Pink', 'Brown', 'Yellow',\n",
        "    'Cyan', 'Magenta', 'Lime', 'Teal', 'Lavender', 'Maroon', 'Navy', 'Olive', 'Silver', 'Gold',\n",
        "    'Indigo', 'Turquoise', 'Beige', 'Crimson', 'Salmon','Tan','Lime', 'Fuchsia', 'Plum',\n",
        "    'Tomato', 'Violet']\n",
        "\n",
        "class TextStyle:\n",
        "    # Font Styles\n",
        "    BOLD = '\\033[1m'\n",
        "    DIM = '\\033[2m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "    BLINK = '\\033[5m'\n",
        "    REVERSE = '\\033[7m'\n",
        "    RESET_ALL = '\\033[0m'\n",
        "\n",
        "    # Font Colors\n",
        "    BLACK = '\\033[30m'\n",
        "    RED = '\\033[31m'\n",
        "    GREEN = '\\033[32m'\n",
        "    YELLOW = '\\033[33m'\n",
        "    BLUE = '\\033[34m'\n",
        "    MAGENTA = '\\033[35m'\n",
        "    CYAN = '\\033[36m'\n",
        "    WHITE = '\\033[37m'\n",
        "\n",
        "    # Background Colors\n",
        "    BG_BLACK = '\\033[40m'\n",
        "    BG_RED = '\\033[41m'\n",
        "    BG_GREEN = '\\033[42m'\n",
        "    BG_YELLOW = '\\033[43m'\n",
        "    BG_BLUE = '\\033[44m'\n",
        "    BG_MAGENTA = '\\033[45m'\n",
        "    BG_CYAN = '\\033[46m'\n",
        "    BG_WHITE = '\\033[47m'\n"
      ],
      "metadata": {
        "id": "QoDBlBIgCCTw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ---- definition ---- ##\n",
        "\n",
        "NUM_DISCRIMINATORS = 3\n",
        "GENERATOR_DROPOUT_RATE = 0.2  #0.1\n",
        "DISCRIMINATOR_DROPOUT_RATE = 0.3      #Adjust the dropout rate to prevent overfitting during training.\n",
        "LEAKY_RELU_ALPA = 0.2\n",
        "\n",
        "NUM_EPOCHS = 500      #1000\n",
        "BATCH_SIZE = 128      #30\n",
        "OPTIMIZER_LR = 0.0001                 # learning rate\n",
        "OPTIMIZER_BETAS = (0.5, 0.999)\n",
        "\n",
        "# Save losses for plotting\n",
        "d0_real_losses = []   # left discriminator losses   (disc 0)\n",
        "d0_fake_losses = []   # left discriminator losses   (disc 0)\n",
        "d0_losses      = []   # discriminator losses        (disc 0)\n",
        "\n",
        "d1_real_losses = []   # Middle discriminator losses (disc 1)\n",
        "d1_fake_losses = []   # Middle discriminator losses (disc 1)\n",
        "d1_losses      = []   # discriminator losses        (disc 1)\n",
        "\n",
        "d2_real_losses = []   # right discriminator losses  (disc 2)\n",
        "d2_fake_losses = []   # right discriminator losses  (disc 2)\n",
        "d2_losses      = []   # discriminator losses        (disc 2)\n",
        "\n",
        "g_losses       = []   # generator losses\n",
        "d_losses       = []   # discriminator losses\n",
        "\n"
      ],
      "metadata": {
        "id": "ToVmmhnnB8T9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ---- Read CSV Files ---- ##\n",
        "\n",
        "\"\"\" ----------------- Read CSV File Function ----------------- \"\"\"\n",
        "def read_csv_files(dataset_directory, percent):\n",
        "  print(f\"{TextStyle.BOLD}{TextStyle.BLUE}------------ Read CSV Files ------------{TextStyle.RESET_ALL}\")\n",
        "\n",
        "  files = [f for f in os.listdir(dataset_directory) if f.endswith('.csv')]\n",
        "\n",
        "  if files == []:\n",
        "    print('Not found any csv files')\n",
        "  else:\n",
        "    print('Your files are: ', files)\n",
        "\n",
        "    np_array_values = []\n",
        "    data_df = pd.DataFrame()\n",
        "    firstFile = True\n",
        "\n",
        "    for file in files:\n",
        "      file_path = os.path.join(dataset_directory, file)   # csv_file_path\n",
        "      print('File Path: ', file_path)\n",
        "\n",
        "      try:\n",
        "        df = ''\n",
        "        df = pd.read_csv(file_path, encoding = \"ISO-8859-1\")  #.head()   #,low_memory=False   ISO-8859-1\n",
        "        total_rows = len(df)\n",
        "        print('Total rows in df/file: ', total_rows)\n",
        "\n",
        "        num_rows = int(total_rows * (percent / 100))\n",
        "        print('Total rows in df/file 100%: ', num_rows)\n",
        "\n",
        "\n",
        "        \"\"\" Start From Teacher Code \"\"\"\n",
        "        # Generate a list of random indices\n",
        "        random_indices = random.sample(range(total_rows), num_rows)\n",
        "        #print('random_indices: ' , random_indices)\n",
        "\n",
        "        # Select the random rows from the DataFrame\n",
        "        temp_df = df.iloc[random_indices]\n",
        "        if(firstFile):\n",
        "          # Concatenate all DataFrames into one\n",
        "          data_df = temp_df.copy()\n",
        "          firstFile = False\n",
        "        else:\n",
        "          # Concatenate all DataFrames into one\n",
        "          data_df = pd.concat([data_df,temp_df], ignore_index=True)\n",
        "\n",
        "        print(data_df)\n",
        "        return data_df\n",
        "        \"\"\" End From Teacher Code \"\"\"\n",
        "\n",
        "        ## Add DataFrame to new CSV file\n",
        "        #new_csv_file_path = os.path.join(dataset_directory, 'new_sqli.csv')  # \"/content/dataset/new_sqli.csv\"\n",
        "        #df.to_csv(new_csv_file_path, index=False)\n",
        "\n",
        "      except Exception as e:\n",
        "        print('Can not Read File called : ', file)\n",
        "        print('File path: ', file_path)\n",
        "        print(\"Errpr Exception e : \", e)\n",
        "\n",
        "\n",
        "# ---------------------------> Read Data of CSV Files <--------------------------- #\n",
        "dataset_directory = \"/content/datasets\"   #files_path\n",
        "percent = 100\n",
        "df = read_csv_files(dataset_directory,percent)\n",
        "print('len data : ' , len(df))\n",
        "\n",
        "class_Col = 'attack_type'\n",
        "min_rows_per_class = 2000  #50000\n",
        "origin_data = df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if08PaanCVrW",
        "outputId": "e3ede094-4962-46bc-9491-1458cc5e9c91"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[34m------------ Read CSV Files ------------\u001b[0m\n",
            "Your files are:  ['before_only_4000.csv']\n",
            "File Path:  /content/datasets/before_only_4000.csv\n",
            "Total rows in df/file:  4000\n",
            "Total rows in df/file 100%:  4000\n",
            "                                               sentence  attack_type  \\\n",
            "2535                                          salamanca            0   \n",
            "871    UNION ALL SELECT NULL, NULL, NULL, NULL, NULL...            1   \n",
            "917               1 where 8102 = 8102 and 9198 = 9198--            1   \n",
            "1882  \"  )  )   UNION ALL SELECT NULL, NULL, NULL, N...            1   \n",
            "3015                                   urgeles montanuy            0   \n",
            "...                                                 ...          ...   \n",
            "1057  1' or exp ( ~ ( select * from  ( select concat...            1   \n",
            "758   \"  )  )   )  UNION ALL SELECT NULL, NULL, NULL...            1   \n",
            "2393                                         es93n576te            0   \n",
            "2180                                     buils szebesta            0   \n",
            "540                              end and 'hizd' = 'hizd            1   \n",
            "\n",
            "      len_payload  \n",
            "2535            9  \n",
            "871            59  \n",
            "917            37  \n",
            "1882          239  \n",
            "3015           16  \n",
            "...           ...  \n",
            "1057          159  \n",
            "758           221  \n",
            "2393           10  \n",
            "2180           14  \n",
            "540            22  \n",
            "\n",
            "[4000 rows x 3 columns]\n",
            "len data :  4000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ---- Pre-process ---- ##\n",
        "print(f\"{TextStyle.BOLD}{TextStyle.BLUE}------------ Pre-Proccess ------------{TextStyle.RESET_ALL}\")\n",
        "\n",
        "\n",
        "# Step 1.1: One-hot encode attack_type\n",
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "y = encoder.fit_transform(df[['attack_type']])\n",
        "\n",
        "\n",
        "# Step 11.2: create X by remove 'attack_type'\n",
        "#new_df_data = df.drop(columns=['attack_type'], inplace=True)\n",
        "new_df = df.copy()\n",
        "#X = new_df.drop(columns=['attack_type'], inplace=True)\n",
        "X = df[['sentence', 'len_payload']]  # Features: 'sentence' and 'len_payload'\n",
        "\n",
        "\n",
        "# Step 11.3: Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# Step 11.4: TfidfVectorizer  ---<<>>--- ( to 'sentence' column)\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=100)  # Set max_features to 50 for simplicity (Limit to top 100 features)   #dtype='float32'\n",
        "## --- X_train\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(X_train['sentence'])            # without Tokenization step\n",
        "X_tfidf_selected_features = tfidf_vectorizer.get_feature_names_out()\n",
        "X_train_tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=X_tfidf_selected_features)     #X_df_tfidf\n",
        "## --- X_test\n",
        "X_test_tfidf_values = tfidf_vectorizer.transform(X_test['sentence'])      # without Tokenization step\n",
        "X_test_tfidf_selected_features = tfidf_vectorizer.get_feature_names_out()\n",
        "X_test_tfidf_df = pd.DataFrame(X_test_tfidf_values.toarray(), columns=X_test_tfidf_selected_features)\n",
        "\n",
        "x_train_data = X_train_tfidf_df\n",
        "x_test_data = X_test_tfidf_df\n",
        "# Step 11.5: Concatenate TF-IDF features with 'len_payload' column\n",
        "# First, drop the 'sentence' column from X_train and X_test and then concatenate with TF-IDF features\n",
        "#x_train_data = pd.concat([X_train.drop(columns=['sentence']).reset_index(drop=True), X_train_tfidf_df], axis=1)\n",
        "#x_test_data = pd.concat([X_test.drop(columns=['sentence']).reset_index(drop=True), X_test_tfidf_df], axis=1)\n",
        "###x_train_data = pd.concat([ X_train.drop(columns=['sentence'], inplace=True) , X_train_tfidf_df], axis=1)\n",
        "###x_test_data = pd.concat([ X_test.drop(columns=['sentence'], inplace=True)  , X_test_tfidf_df], axis=1)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "# Step 11.6: Apply MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(x_train_data)     # Scale all features (TF-IDF + len_payload)\n",
        "x_train_data_scaled = pd.DataFrame(X_train_scaled, columns=x_train_data.columns)     #X_train_scaled_df\n",
        "\n",
        "X_test_scaled = scaler.fit_transform(x_test_data)     # Scale all features (TF-IDF + len_payload)\n",
        "x_test_data_scaled = pd.DataFrame(X_test_scaled, columns=x_test_data.columns)        #X_test_scaled_df\n",
        "\n",
        "\n",
        "# Step 11.7: Combine features using np.hstack\n",
        "# We want to combine the scaled TF-IDF features with the 'len_payload' feature, which is already scaled\n",
        "X_train_combined = np.hstack([x_train_data_scaled.values])  # For training data\n",
        "X_test_combined = np.hstack([x_test_data_scaled.values])    # For test data\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# Step 11.5: Apply MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "## --- X_train\n",
        "len_payload_scaled_train = scaler.fit_transform(X_train[['len_payload']])    # Only scale the 'len_payload' column\n",
        "len_payload_scaled_train_df = pd.DataFrame(len_payload_scaled_train, columns=['len_payload_scaled'])\n",
        "X_train_tfidf_scaled = scaler.fit_transform(x_train_data)     # Only scale the TF-IDF Data --- (because we used GAN Model and tanh in generator)\n",
        "#x_tfidf_train_data = pd.DataFrame(X_train_tfidf_scaled, columns=X_train_tfidf_df.columns)     #X_train_scaled_df\n",
        "\n",
        "## --- X_test\n",
        "len_payload_scaled_test = scaler.fit_transform(X_test[['len_payload']])    # Only scale the 'len_payload' column\n",
        "len_payload_scaled_test_df = pd.DataFrame(len_payload_scaled_test, columns=['len_payload_scaled'])\n",
        "X_test_tfidf_scaled = scaler.fit_transform(x_test_data)     # Only scale the TF-IDF Data --- (because we used GAN Model and tanh in generator)\n",
        "#x_tfidf_test_data = pd.DataFrame(X_test_tfidf_scaled, columns=X_test_tfidf_df.columns)        #X_test_scaled_df\n",
        "\n",
        "\n",
        "\n",
        "# Step 11.6: Combine all features (scaled TF-IDF + scaled len_payload) into a single matrix using np.hstack\n",
        "# Use np.hstack to horizontally stack TF-IDF (scaled) features and scaled len_payload features\n",
        "X_train_combined = np.hstack([X_train_tfidf_scaled, len_payload_scaled_train_df.values])        ## --- X_train\n",
        "X_test_combined = np.hstack([X_test_tfidf_scaled, len_payload_scaled_test_df.values])           ## --- X_test\n",
        "#X_train_combined = np.hstack([x_tfidf_train_data.values, len_payload_scaled_train_df.values])  ## --- X_train\n",
        "#X_test_combined = np.hstack([x_tfidf_test_data.values, len_payload_scaled_test_df.values])     ## --- X_test\n",
        "\n",
        "\n",
        "\n",
        "# Step 11.7: Apply PCA for dimensionality reduction (Optional)\n",
        "#pca = PCA(n_components=50)  # Reduce to 50 components\n",
        "pca = PCA(n_components=0.85, random_state=453)    #0.95\n",
        "\n",
        "X_train_data = pca.fit_transform(X_train_combined)      #x_train_data     ## --- X_train\n",
        "X_test_data = pca.transform(X_test_combined)            #x_test_data      ## --- X_test\n",
        "\n",
        "# Convert PCA results back to DataFrames and concatenate with the original non-sentence columns\n",
        "train_pca_feature_names = [f'pca_{i+1}' for i in range(X_train_data.shape[1])]          # Generate new feature names for PCA components\n",
        "X_train_data_df = pd.DataFrame(data=X_train_data, columns=train_pca_feature_names)      # Create a DataFrame with the PCA-transformed data\n",
        "x_train_data = X_train_data_df\n",
        "\n",
        "test_pca_feature_names = [f'pca_{i+1}' for i in range(X_test_data.shape[1])]\n",
        "X_test_data_df = pd.DataFrame(data=X_test_data, columns=test_pca_feature_names)\n",
        "x_test_data = X_test_data_df\n",
        "\n",
        "\n",
        "# variance ratio : show how much information (variance) can be attributed to each of the principal components.\n",
        "explained_variance_ratio = pca.explained_variance_ratio_          # Calculate explained variance ratio and cumulative variance\n",
        "cumulative_variance      = np.cumsum(explained_variance_ratio)    # Calculates the cumulative explained variance ratio for each component.\n",
        "\n",
        "\n",
        "# Plot component variance and cumulative variance\n",
        "plt.figure(figsize=(12, 4))\n",
        "colors_list = ['Red','Orange', 'Blue', 'Purple','Green','Pink','Gray','Tan','Lime','Cyan']\n",
        "\n",
        "# Plot component variance with percentages\n",
        "plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio * 100, label='Component Variance')\n",
        "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance * 100, marker='o', color='r', label='Cumulative Variance')\n",
        "\n",
        "plt.title('Variance Explained by Principal Components\\n Dataset ')\n",
        "plt.xlabel('Principal Component')\n",
        "plt.ylabel('Percentage of Variance Explained (%)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "U5GvtbTcCYbj",
        "outputId": "4a2b72c5-f2e2-4fb0-e72e-64f2161cb056"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[34m------------ Pre-Proccess ------------\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Step 11.4: TfidfVectorizer  ---<<>>--- ( to 'sentence' column)\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=100)  # Set max_features to 50 for simplicity (Limit to top 100 features)   #dtype='float32'\n",
        "## --- X_train\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(X_train['sentence'])            # without Tokenization step\n",
        "X_tfidf_selected_features = tfidf_vectorizer.get_feature_names_out()\n",
        "X_train_tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=X_tfidf_selected_features)\n",
        "#x_train_data = pd.concat([ X_train.drop(columns=['sentence'], inplace=True) , X_train_tfidf_df], axis=1)\n",
        "\n",
        "## --- X_test\n",
        "X_test_tfidf_values = tfidf_vectorizer.transform(X_test['sentence'])      # without Tokenization step\n",
        "X_test_tfidf_selected_features = tfidf_vectorizer.get_feature_names_out()\n",
        "X_test_tfidf_df = pd.DataFrame(X_test_tfidf_values.toarray(), columns=X_test_tfidf_selected_features)\n",
        "#x_test_data = pd.concat([ X_test.drop(columns=['sentence'], inplace=True)  , X_test_tfidf_df], axis=1)\n",
        "\n",
        "\n",
        "# Step 11.5: Concatenate TF-IDF features with 'len_payload' column\n",
        "# First, drop the 'sentence' column from X_train and X_test and then concatenate with TF-IDF features\n",
        "x_train_data = pd.concat([X_train.drop(columns=['sentence']).reset_index(drop=True), X_train_tfidf_df], axis=1)\n",
        "x_test_data = pd.concat([X_test.drop(columns=['sentence']).reset_index(drop=True), X_test_tfidf_df], axis=1)\n",
        "\n",
        "###x_train_data = pd.concat([ X_train.drop(columns=['sentence'], inplace=True) , X_train_tfidf_df], axis=1)\n",
        "###x_test_data = pd.concat([ X_test.drop(columns=['sentence'], inplace=True)  , X_test_tfidf_df], axis=1)\n",
        "\n",
        "\n",
        "# Step 11.6: Apply MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(x_train_data)     # Scale all features (TF-IDF + len_payload)\n",
        "x_train_data_scaled = pd.DataFrame(X_train_scaled, columns=x_train_data.columns)     #X_train_scaled_df\n",
        "\n",
        "X_test_scaled = scaler.fit_transform(x_test_data)     # Scale all features (TF-IDF + len_payload)\n",
        "x_test_data_scaled = pd.DataFrame(X_test_scaled, columns=x_test_data.columns)        #X_test_scaled_df\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "# Step 11.5: Apply MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "## --- X_train\n",
        "len_payload_scaled_train = scaler.fit_transform(X_train[['len_payload']])    # Only scale the 'len_payload' column\n",
        "len_payload_scaled_train_df = pd.DataFrame(len_payload_scaled_train, columns=['len_payload_scaled'])\n",
        "X_train_tfidf_scaled = scaler.fit_transform(X_train_tfidf_df)     # Only scale the TF-IDF Data --- (because we used GAN Model and tanh in generator)\n",
        "#x_tfidf_train_data = pd.DataFrame(X_train_tfidf_scaled, columns=X_train_tfidf_df.columns)     #X_train_scaled_df\n",
        "\n",
        "## --- X_test\n",
        "len_payload_scaled_test = scaler.fit_transform(X_test[['len_payload']])    # Only scale the 'len_payload' column\n",
        "len_payload_scaled_test_df = pd.DataFrame(len_payload_scaled_test, columns=['len_payload_scaled'])\n",
        "X_test_tfidf_scaled = scaler.fit_transform(X_test_tfidf_df)     # Only scale the TF-IDF Data --- (because we used GAN Model and tanh in generator)\n",
        "#x_tfidf_test_data = pd.DataFrame(X_test_tfidf_scaled, columns=X_test_tfidf_df.columns)        #X_test_scaled_df\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Step 11.7: Combine features using np.hstack\n",
        "# We want to combine the scaled TF-IDF features with the 'len_payload' feature, which is already scaled\n",
        "X_train_combined = np.hstack([x_train_data_scaled.values])  # For training data\n",
        "X_test_combined = np.hstack([x_test_data_scaled.values])    # For test data\n",
        "\n",
        "\"\"\"\n",
        "# Step 11.6: Combine all features (scaled TF-IDF + scaled len_payload) into a single matrix using np.hstack\n",
        "# Use np.hstack to horizontally stack TF-IDF (scaled) features and scaled len_payload features\n",
        "## --- X_train\n",
        "#X_train_combine_data = np.hstack([x_tfidf_train_data.values, len_payload_scaled_train_df.values])\n",
        "X_train_combine_data = np.hstack([X_train_tfidf_scaled, len_payload_scaled_train_df.values])\n",
        "\n",
        "## --- X_test\n",
        "#X_test_combine_data = np.hstack([x_tfidf_test_data.values, len_payload_scaled_test_df.values])\n",
        "X_test_combine_data = np.hstack([X_test_tfidf_scaled, len_payload_scaled_test_df.values])\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Step 11.7: Apply PCA for dimensionality reduction (Optional)\n",
        "pca = PCA(n_components=50)  # Reduce to 50 components\n",
        "## --- X_train\n",
        "X_train_data = pca.fit_transform(X_train_combined)\n",
        "\n",
        "## --- X_test\n",
        "X_test_data = pca.transform(X_test_combined)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DVCzgjJHVg85"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "# Step 1.2: TfidfVectorizer  ---<<>>--- ( to 'sentence' column)\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=100)  # Set max_features to 50 for simplicity (Limit to top 100 features)  #dtype='float32'\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['sentence']) #.toarray()            # without Tokenization step\n",
        "X_tfidf_selected_features = tfidf_vectorizer.get_feature_names_out()\n",
        "X_df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=X_tfidf_selected_features)\n",
        "\n",
        "## ----- remove origin sentence ------<<\n",
        "# Concatenate TF-IDF features with the original data excluding the sentence column\n",
        "x_tfidf_data = pd.concat([ df.drop(columns=['sentence', 'attack_type'], inplace=True) , X_df_tfidf], axis=1)\n",
        "\n",
        "\n",
        "# Step 1.3: Apply MinMaxScaler to the 'len_payload' column\n",
        "scaler = MinMaxScaler()\n",
        "len_payload_scaled = scaler.fit_transform(df[['len_payload']])    # Only scale the 'len_payload' column\n",
        "len_payload_scaled_df = pd.DataFrame(len_payload_scaled, columns=['len_payload_scaled'])\n",
        "\n",
        "# Step 1.4: Apply MinMaxScaler to the TF-IDF Data (optional)   ----<<>>----  because we used GAN Model and tanh in generator\n",
        "X_tfidf_scaled = scaler.fit_transform(x_tfidf_data) #df[['len_payload']])   #X_df_tfidf\n",
        "\n",
        "\n",
        "# Step 1.4: Combine all features (Tfidf + len_payload) into a single matrix\n",
        "#X = np.hstack([X_tfidf, len_payload_scaled])\n",
        "# Step 1.5: Combine all features (scaled TF-IDF + scaled len_payload) into a single matrix using np.hstack\n",
        "# Use np.hstack to horizontally stack TF-IDF (scaled) features and scaled len_payload features\n",
        "X = np.hstack([X_tfidf_scaled, len_payload_scaled_df.values])\n",
        "\n",
        "\n",
        "# Step 1.6: Apply PCA for dimensionality reduction (Optional)\n",
        "pca = PCA(n_components=10)  # Reduce to 10 components\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "# Step 1.7: Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "kWAtn-TX7hU8",
        "outputId": "7b5da57b-d51d-4333-a1c7-1b509e21391d"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Step 1.2: TfidfVectorizer  ---<<>>--- ( to 'sentence' column)\\ntfidf_vectorizer = TfidfVectorizer(max_features=100)  # Set max_features to 50 for simplicity (Limit to top 100 features)  #dtype='float32'\\nX_tfidf = tfidf_vectorizer.fit_transform(df['sentence']) #.toarray()            # without Tokenization step\\nX_tfidf_selected_features = tfidf_vectorizer.get_feature_names_out()\\nX_df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=X_tfidf_selected_features)\\n\\n## ----- remove origin sentence ------<<\\n# Concatenate TF-IDF features with the original data excluding the sentence column\\nx_tfidf_data = pd.concat([ df.drop(columns=['sentence', 'attack_type'], inplace=True) , X_df_tfidf], axis=1)\\n\\n\\n# Step 1.3: Apply MinMaxScaler to the 'len_payload' column\\nscaler = MinMaxScaler()\\nlen_payload_scaled = scaler.fit_transform(df[['len_payload']])    # Only scale the 'len_payload' column\\nlen_payload_scaled_df = pd.DataFrame(len_payload_scaled, columns=['len_payload_scaled'])\\n\\n# Step 1.4: Apply MinMaxScaler to the TF-IDF Data (optional)   ----<<>>----  because we used GAN Model and tanh in generator\\nX_tfidf_scaled = scaler.fit_transform(x_tfidf_data) #df[['len_payload']])   #X_df_tfidf\\n\\n\\n# Step 1.4: Combine all features (Tfidf + len_payload) into a single matrix\\n#X = np.hstack([X_tfidf, len_payload_scaled])\\n# Step 1.5: Combine all features (scaled TF-IDF + scaled len_payload) into a single matrix using np.hstack\\n# Use np.hstack to horizontally stack TF-IDF (scaled) features and scaled len_payload features\\nX = np.hstack([X_tfidf_scaled, len_payload_scaled_df.values])\\n\\n\\n# Step 1.6: Apply PCA for dimensionality reduction (Optional)\\npca = PCA(n_components=10)  # Reduce to 10 components\\nX_pca = pca.fit_transform(X)\\n\\n# Step 1.7: Train-Test Split\\nX_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ---- GAN Models ---- ##\n",
        "\n",
        "# Generator Model\n",
        "def build_generator(latent_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=latent_dim))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dense(X_train_data.shape[1], activation='tanh'))  # Output layer matches input size\n",
        "    return model\n",
        "\n",
        "# Discriminator Model\n",
        "def build_discriminator(input_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, input_dim=input_dim))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dense(128))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))  # Binary output\n",
        "    return model\n",
        "\n",
        "# Combined Model (Generator + Discriminator)\n",
        "def build_gan(generator, discriminator):\n",
        "    discriminator.trainable = False   # Freeze discriminator during generator training\n",
        "    model = Sequential()\n",
        "    model.add(generator)\n",
        "    model.add(discriminator)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def build_generator_2(latent_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=latent_dim, activation='relu'))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(X_train_data.shape[1], activation='sigmoid'))  # Output layer to match input shape of X\n",
        "    return model\n",
        "\n",
        "def build_discriminator_2(input_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, input_dim=input_dim, activation='relu'))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))  # Binary classification (real or fake)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# Step 3: Compile Models\n",
        "latent_dim = 100  # Latent dimension for generator input\n",
        "\n",
        "# Build models\n",
        "print(f\"{TextStyle.BOLD}{TextStyle.BLUE}------------ GAN Models ------------{TextStyle.RESET_ALL}\")\n",
        "generator = build_generator(latent_dim)\n",
        "discriminator = build_discriminator(X_train_data.shape[1])\n",
        "gan = build_gan(generator, discriminator)\n",
        "\n",
        "# Compile discriminator\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Compile GAN\n",
        "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-F-ggQiDLPb",
        "outputId": "3803a05e-b488-4426-8a86-f0466e00ab71"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[34m------------ GAN Models ------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ---- Step 4: Train GAN Models ---- ##\n",
        "\n",
        "def train_gan(generator, discriminator, gan, X_train, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE):     ## epochs=1000 // 500  ,  batch_size=32    // 128  #30\n",
        "    half_batch = batch_size // 2\n",
        "    batch_count = X_train.shape[0]   #batch_size\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Train Discriminator with real data\n",
        "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "        real_data = X_train[idx]\n",
        "        real_labels = np.ones((batch_size, 1))  # Labels for real data (1)\n",
        "\n",
        "        # Train Discriminator with fake data generated by Generator\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "        generated_data = generator.predict(noise)\n",
        "        generated_labels = np.zeros((batch_size, 1))  # Labels for fake data (0)\n",
        "\n",
        "        # Train the Discriminator (real + fake/generated)\n",
        "        d_loss_real = discriminator.train_on_batch(real_data, real_labels)\n",
        "        d_loss_fake = discriminator.train_on_batch(generated_data, generated_labels)\n",
        "\n",
        "        # Train Generator (through the combined model)\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "        valid_labels = np.ones((batch_size, 1))  # Labels for \"real\" data (target for generator)\n",
        "        g_loss = gan.train_on_batch(noise, valid_labels)\n",
        "\n",
        "        # Print progress\n",
        "        if epoch % 100 == 0 or epoch == NUM_EPOCHS:\n",
        "          print(f\"{epoch}/{epochs} [D loss real: {d_loss_real[0]} | D loss fake: {d_loss_fake[0]}] [G loss: {g_loss}]\")\n",
        "\n",
        "\n",
        "# Train GAN\n",
        "train_gan(generator, discriminator, gan, X_train_data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHjmXgZBDhpc",
        "outputId": "fac05264-14c8-4a3f-af20-bf067fc4472c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 5ms/step\n",
            "0/500 [D loss real: 0.6673203706741333 | D loss fake: 0.734492301940918] [G loss: 0.5946036577224731]\n",
            "4/4 [==============================] - 0s 11ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 12ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 12ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 12ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 11ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "100/500 [D loss real: 0.6694577932357788 | D loss fake: 1.4191498756408691] [G loss: 0.2766081690788269]\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "200/500 [D loss real: 0.6698259711265564 | D loss fake: 1.4240305423736572] [G loss: 0.27609336376190186]\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "300/500 [D loss real: 0.6679525375366211 | D loss fake: 1.4268798828125] [G loss: 0.27428221702575684]\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "400/500 [D loss real: 0.6691009998321533 | D loss fake: 1.4304022789001465] [G loss: 0.27335163950920105]\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ---- Step 5: Balance Data Using GAN ---- ##\n",
        "\n",
        "# Generate synthetic samples using the trained generator\n",
        "def generate_synthetic_data(generator, num_samples=1000):\n",
        "    noise = np.random.normal(0, 1, (num_samples, latent_dim))\n",
        "    synthetic_data = generator.predict(noise)\n",
        "    return synthetic_data\n",
        "\n",
        "# Generate synthetic samples\n",
        "synthetic_samples = generate_synthetic_data(generator, num_samples=1000)\n",
        "\n",
        "# Combine synthetic data with real data for balancing\n",
        "balanced_data = np.vstack([X_test_data, synthetic_samples])\n",
        "#balanced_labels = np.vstack([y_train, y_train[:synthetic_samples.shape[0]]])  # Add similar labels\n",
        "balanced_labels = np.vstack([np.ones((X_test_data.shape[0], 1)), np.zeros((synthetic_samples.shape[0], 1))])  # Real = 1, Fake = 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFxkCZX4D8Tz",
        "outputId": "bd5d4abc-425d-4902-b0f2-087a10a51a34"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ---- Evaluate GAN Model ---- ##\n",
        "\n",
        "# Evaluate the discriminator on the balanced data\n",
        "_, accuracy = discriminator.evaluate(balanced_data, balanced_labels)\n",
        "print(f\"Discriminator Accuracy on Balanced Data: {accuracy * 100}%\")\n",
        "\n",
        "# Plot loss during training (optional)\n",
        "# You can store the loss values during training and plot them after training\n",
        "\n",
        "# Optional: Visualize results using PCA for dimensionality reduction\n",
        "#reduced_data = PCA(n_components=2).fit_transform(balanced_data)\n",
        "#plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=balanced_labels[:, 0])\n",
        "#plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq7MvsJ8EEdI",
        "outputId": "54d552bc-71cc-4120-b64f-ec7efa24aabc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 0s 2ms/step - loss: 1.0921 - accuracy: 0.4400\n",
            "Discriminator Accuracy on Balanced Data: 43.99999976158142%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My Code"
      ],
      "metadata": {
        "id": "keICpSqFLc-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main"
      ],
      "metadata": {
        "id": "BiBDDITbL7aC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ----- Libraries ----- ##\n",
        "#for read csv file\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "# pre-process\n",
        "##for stop word\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "## not used now\n",
        "#import unicodedata     # Remove accents\n",
        "#import string\n",
        "\n",
        "\n",
        "import sklearn\n",
        "\n",
        "## for tokenization\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import WordPunctTokenizer      ## WordPunctTokenizer --> splits words based on punctuation boundaries.\n",
        "\n",
        "## for divide data to (train / test/ validate)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# for one-hor encode (sentence to 2D)\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# for TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "\n",
        "# for plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# for GAN\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential        ## new\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input,\n",
        "    Concatenate,\n",
        "    Embedding,\n",
        "    Dense,\n",
        "    LeakyReLU,\n",
        "    BatchNormalization,\n",
        "    Dropout,\n",
        "    Reshape,\n",
        "    LSTM\n",
        ")\n",
        "\n",
        "import keras\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt         ## new\n",
        "\n",
        "import time\n",
        "# taqadum in arabic , progress/process in english\n",
        "from tqdm.notebook import tqdm\n",
        "#from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Suppress warnings from numpy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
        "\n",
        "\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# for Evaluate\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#!pip install tensorflow==2.15.0 scikit-learn==1.2.2 keras==2.15.0   #python 3.10.12\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------------------------#\n",
        "\n",
        "\n",
        "print(tf. __version__)      # tensorflow version   2.15.0\n",
        "\n",
        "!python --version           # python version    3.10.12\n",
        "\n",
        "print(sklearn.__version__)         # scikit-learn version    1.2.2\n",
        "\n",
        "print(keras.__version__)           # keras version    2.15.0\n",
        "\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------------------------#\n",
        "\n",
        "\n",
        "## ---- Color + Style Text ---- ##\n",
        "colors_list = [\n",
        "    'Red', 'Green', 'Blue', 'Purple', 'Orange', 'Pink', 'Brown', 'Yellow',\n",
        "    'Cyan', 'Magenta', 'Lime', 'Teal', 'Lavender', 'Maroon', 'Navy', 'Olive', 'Silver', 'Gold',\n",
        "    'Indigo', 'Turquoise', 'Beige', 'Crimson', 'Salmon','Tan','Lime', 'Fuchsia', 'Plum',\n",
        "    'Tomato', 'Violet']\n",
        "\n",
        "class TextStyle:\n",
        "    # Font Styles\n",
        "    BOLD = '\\033[1m'\n",
        "    DIM = '\\033[2m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "    BLINK = '\\033[5m'\n",
        "    REVERSE = '\\033[7m'\n",
        "    RESET_ALL = '\\033[0m'\n",
        "\n",
        "    # Font Colors\n",
        "    BLACK = '\\033[30m'\n",
        "    RED = '\\033[31m'\n",
        "    GREEN = '\\033[32m'\n",
        "    YELLOW = '\\033[33m'\n",
        "    BLUE = '\\033[34m'\n",
        "    MAGENTA = '\\033[35m'\n",
        "    CYAN = '\\033[36m'\n",
        "    WHITE = '\\033[37m'\n",
        "\n",
        "    # Background Colors\n",
        "    BG_BLACK = '\\033[40m'\n",
        "    BG_RED = '\\033[41m'\n",
        "    BG_GREEN = '\\033[42m'\n",
        "    BG_YELLOW = '\\033[43m'\n",
        "    BG_BLUE = '\\033[44m'\n",
        "    BG_MAGENTA = '\\033[45m'\n",
        "    BG_CYAN = '\\033[46m'\n",
        "    BG_WHITE = '\\033[47m'\n"
      ],
      "metadata": {
        "id": "7qFVfuvRLgjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk0A1I0Ax7lE"
      },
      "source": [
        "## **definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16Eb0oBrx7lF"
      },
      "outputs": [],
      "source": [
        "\n",
        "NUM_DISCRIMINATORS = 3\n",
        "GENERATOR_DROPOUT_RATE = 0.2  #0.1\n",
        "DISCRIMINATOR_DROPOUT_RATE = 0.3      #Adjust the dropout rate to prevent overfitting during training.\n",
        "LEAKY_RELU_ALPA = 0.2\n",
        "\n",
        "NUM_EPOCHS = 500      #1000\n",
        "BATCH_SIZE = 128      #30\n",
        "OPTIMIZER_LR = 0.0001                 # learning rate\n",
        "OPTIMIZER_BETAS = (0.5, 0.999)\n",
        "\n",
        "# Save losses for plotting\n",
        "d0_real_losses = []   # left discriminator losses   (disc 0)\n",
        "d0_fake_losses = []   # left discriminator losses   (disc 0)\n",
        "d0_losses      = []   # discriminator losses        (disc 0)\n",
        "\n",
        "d1_real_losses = []   # Middle discriminator losses (disc 1)\n",
        "d1_fake_losses = []   # Middle discriminator losses (disc 1)\n",
        "d1_losses      = []   # discriminator losses        (disc 1)\n",
        "\n",
        "d2_real_losses = []   # right discriminator losses  (disc 2)\n",
        "d2_fake_losses = []   # right discriminator losses  (disc 2)\n",
        "d2_losses      = []   # discriminator losses        (disc 2)\n",
        "\n",
        "g_losses       = []   # generator losses\n",
        "d_losses       = []   # discriminator losses\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn8YhYkbx7lG"
      },
      "source": [
        "## **Read Multi Files csv**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" ----------------- Read CSV File Function ----------------- \"\"\"\n",
        "def read_csv_files(dataset_directory, percent):\n",
        "  print(f\"{TextStyle.BOLD}{TextStyle.BLACK}------------ Handling Read CSV Files ------------{TextStyle.RESET_ALL}\")\n",
        "\n",
        "  files = [f for f in os.listdir(dataset_directory) if f.endswith('.csv')]\n",
        "\n",
        "  if files == []:\n",
        "    print('Not found any csv files')\n",
        "  else:\n",
        "    print('Your files are: ', files)\n",
        "\n",
        "    np_array_values = []\n",
        "    data_df = pd.DataFrame()\n",
        "    firstFile = True\n",
        "\n",
        "    for file in files:\n",
        "      file_path = os.path.join(dataset_directory, file)   # csv_file_path\n",
        "      print('File Path: ', file_path)\n",
        "\n",
        "      try:\n",
        "        df = ''\n",
        "        df = pd.read_csv(file_path, encoding = \"ISO-8859-1\")  #.head()   #,low_memory=False   ISO-8859-1\n",
        "        total_rows = len(df)\n",
        "        print('Total rows in df/file: ', total_rows)\n",
        "\n",
        "        num_rows = int(total_rows * (percent / 100))\n",
        "        print('Total rows in df/file 100%: ', num_rows)\n",
        "\n",
        "\n",
        "        \"\"\" Start From Teacher Code \"\"\"\n",
        "        # Generate a list of random indices\n",
        "        random_indices = random.sample(range(total_rows), num_rows)\n",
        "        #print('random_indices: ' , random_indices)\n",
        "\n",
        "        # Select the random rows from the DataFrame\n",
        "        temp_df = df.iloc[random_indices]\n",
        "        if(firstFile):\n",
        "          # Concatenate all DataFrames into one\n",
        "          data_df = temp_df.copy()\n",
        "          firstFile = False\n",
        "        else:\n",
        "          # Concatenate all DataFrames into one\n",
        "          data_df = pd.concat([data_df,temp_df], ignore_index=True)\n",
        "\n",
        "        print(data_df)\n",
        "        return data_df\n",
        "        \"\"\" End From Teacher Code \"\"\"\n",
        "\n",
        "        ## Add DataFrame to new CSV file\n",
        "        #new_csv_file_path = os.path.join(dataset_directory, 'new_sqli.csv')  # \"/content/dataset/new_sqli.csv\"\n",
        "        #df.to_csv(new_csv_file_path, index=False)\n",
        "\n",
        "      except Exception as e:\n",
        "        print('Can not Read File called : ', file)\n",
        "        print('File path: ', file_path)\n",
        "        print(\"Errpr Exception e : \", e)\n",
        "\n",
        "\n",
        "#\"\"\" ----------------- Apply Code ----------------- \"\"\"\n",
        "#dataset_directory = \"/content/datasets\"   #files_path\n",
        "#percent = 100\n",
        "#data = read_csv_files(dataset_directory,percent)\n"
      ],
      "metadata": {
        "id": "-SXIVMCWN-Ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Decode Payload**"
      ],
      "metadata": {
        "id": "ohDywKWX0zcp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: It can be tricky to differentiate between base64 and normal text with short strings like \"cdiz\" because it could theoretically be either."
      ],
      "metadata": {
        "id": "MSvLEYhwaCAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import urllib.parse\n",
        "import re\n",
        "\n",
        "### ------------- Decode functions (unicode_decode / url_decode / base64_decode / unicode_url_decoding) ------------- ###\n",
        "def unicode_decode(str):\n",
        "  return str.encode('utf-8').decode('unicode-escape') , 'unicode_decode'\n",
        "\n",
        "def url_decode(str):\n",
        "  # Regex to match '%XX' where XX is two hexadecimal digits\n",
        "  is_url_encoded = bool(re.search(r'%[0-9A-Fa-f]{2}', str))\n",
        "  if is_url_encoded :\n",
        "      #return urllib.parse.unquote(str)\n",
        "      try:\n",
        "        decoded_text = urllib.parse.unquote(str)\n",
        "\n",
        "        # Check if the decoded str makes sense\n",
        "        if decoded_text != str:\n",
        "            return decoded_text, \"url_decode\"\n",
        "      except Exception:\n",
        "        pass\n",
        "      return str, \"nomal\"\n",
        "\n",
        "\n",
        "def base64_decode(base64_string):\n",
        "  base64_bytes = base64_string.encode(\"utf-8\")\n",
        "  sample_string_bytes = base64.b64decode(base64_bytes)\n",
        "  sample_str = sample_string_bytes.decode(\"utf-8\")\n",
        "  return sample_str , 'base64'\n",
        "\n",
        "\"\"\"\n",
        "def base64_decode(sql_payload):\n",
        "  return  base64.b64decode(sql_payload).decode('utf-8') , 'base64'\n",
        "\"\"\"\n",
        "\n",
        "def unicode_url_decoding(sql_payload):\n",
        "\n",
        "  if '%20' in sql_payload or '%' in sql_payload:\n",
        "    try:\n",
        "      d_payload, payload_type = url_decode(sql_payload)\n",
        "    except: # Exception as e:\n",
        "      #print(f\"Decoding error in - unicode_url_decoding() - with: {e}\")\n",
        "      d_payload = sql_payload\n",
        "      payload_type = 'normal'\n",
        "\n",
        "  elif sql_payload.startswith(('\\\\u', '\\\\U', '\\\\\\\\u', '\\\\\\\\U')) :\n",
        "    try:\n",
        "      sql_payload = sql_payload.replace(\"\\\\\\\\\", \"\\\\\")\n",
        "      d_payload, payload_type = unicode_decode(sql_payload)\n",
        "      payload_type = 'unicode_decode'\n",
        "    except: # Exception as e:\n",
        "      d_payload = sql_payload\n",
        "      payload_type = 'normal'\n",
        "\n",
        "  else:\n",
        "    d_payload = sql_payload\n",
        "    payload_type = 'normal'\n",
        "\n",
        "  return d_payload, payload_type\n",
        "\n",
        "\n",
        "\n",
        "### ------------- Decode function ------------- ###\n",
        "def decode_payload(sql_payload):\n",
        "  if sql_payload[-1] == '=' and sql_payload[-2] == '=':         # when base64 end with ==\n",
        "    try:\n",
        "      base64_payload = base64_decode(sql_payload)               # 1. base64 decode\n",
        "      if base64_payload != sql_payload :\n",
        "        decode_payload, payload_type = unicode_url_decoding(base64_payload)\n",
        "        payload_type = '' if payload_type == 'normal' else payload_type\n",
        "        payload_type = 'base64_' + payload_type\n",
        "      else:\n",
        "        decode_payload, payload_type = unicode_url_decoding(sql_payload)\n",
        "    except Exception as e:\n",
        "        decode_payload, payload_type = unicode_url_decoding(sql_payload)\n",
        "\n",
        "  else:\n",
        "    #sql_payload += '=='     # when base64 NOT end with == add it\n",
        "    try:\n",
        "      base64_payload = base64_decode(sql_payload)\n",
        "      if base64_payload !=  sql_payload :\n",
        "        decode_payload, payload_type = unicode_url_decoding(base64_payload)\n",
        "        payload_type = '' if payload_type == 'normal' else payload_type\n",
        "        payload_type = 'base64_' + payload_type\n",
        "      else:\n",
        "        decode_payload, payload_type = unicode_url_decoding(sql_payload)\n",
        "    except Exception as e:\n",
        "      #sql_payload = sql_payload[:-2]      # remove last 2 chat == added in this section\n",
        "      decode_payload, payload_type = unicode_url_decoding(sql_payload)\n",
        "\n",
        "  #decode_payload = decode_payload.lower()\n",
        "\n",
        "  return decode_payload , payload_type\n",
        "\n",
        "\n",
        "### ------------- main ------------- ###\n",
        "# Example usage:\n",
        "sql_payload = \"\\\\u0053\\\\u0045\\\\u004C\\\\u0045\\\\u0043\\\\u0054\\\\u0020\\\\u002A\\\\u0020\\\\u0046\\\\u0052\\\\u004F\\\\u004D\\\\u0020\\\\u0075\\\\u0073\\\\u0065\\\\u0072\\\\u0073\\\\u0020\\\\u0057\\\\u0048\\\\u0045\\\\u0052\\\\u0045\\\\u0020\\\\u0075\\\\u0073\\\\u0065\\\\u0072\\\\u006E\\\\u0061\\\\u006D\\\\u0065\\\\u003D\\\\u0027\\\\u006A\\\\u006F\\\\u0068\\\\u006E\\\\u0027\\\\u003B\"   # unicode encoded\n",
        "#sql_payload = \"SELECT%20*%20FROM%20users%20WHERE%20username%3D%27john%27%3B\"    # url encoded\n",
        "#sql_payload = \"U0VMRUNUICogRlJPTSB1c2VycyBXSEVSRSB1c2VybmFtZT0nam9obic7==\"      # base64 encoded\n",
        "#sql_payload = \"U0VMRUNUJTIwKiUyMEZST00lMjB1c2VycyUyMFdIRVJFJTIwdXNlcm5hbWUlM0QlMjdqb2huJTI3JTNC\"   # base64 + url encoded\n",
        "#sql_payload = \"XHUwMDUzXHUwMDQ1XHUwMDRDXHUwMDQ1XHUwMDQzXHUwMDU0XHUwMDIwXHUwMDJBXHUwMDIwXHUwMDQ2XHUwMDUyXHUwMDRGXHUwMDREXHUwMDIwXHUwMDc1XHUwMDczXHUwMDY1XHUwMDcyXHUwMDczXHUwMDIwXHUwMDU3XHUwMDQ4XHUwMDQ1XHUwMDUyXHUwMDQ1XHUwMDIwXHUwMDc1XHUwMDczXHUwMDY1XHUwMDcyXHUwMDZFXHUwMDYxXHUwMDZEXHUwMDY1XHUwMDNEXHUwMDI3XHUwMDZBXHUwMDZGXHUwMDY4XHUwMDZFXHUwMDI3XHUwMDNC\"      # base64 + unicode encoded\n",
        "#sql_payload = \"XHUwMDUzXHUwMDQ1XHUwMDRjXHUwMDQ1XHUwMDQzXHUwMDU0XHUwMDIwXHUwMDJhXHUwMDIwXHUwMDQ2XHUwMDUyXHUwMDRmXHUwMDRkXHUwMDIwXHUwMDc1XHUwMDczXHUwMDY1XHUwMDcyXHUwMDczXHUwMDIwXHUwMDU3XHUwMDQ4XHUwMDQ1XHUwMDUyXHUwMDQ1XHUwMDIwXHUwMDc1XHUwMDczXHUwMDY1XHUwMDcyXHUwMDZlXHUwMDYxXHUwMDZkXHUwMDY1XHUwMDNkXHUwMDI3XHUwMDZhXHUwMDZmXHUwMDY4XHUwMDZlXHUwMDI3XHUwMDNi==\"   # base64 + unicode encoded\n",
        "\n",
        "#sql_payload = \"cdiz\"\n",
        "print(\"Befor Decoded payload:\", sql_payload)\n",
        "\n",
        "decoded_payload , payload_type = decode_payload(sql_payload)\n",
        "if decoded_payload:\n",
        "    print(\"After Decoded payload:\", decoded_payload, '  :::  ', payload_type)\n",
        "else:\n",
        "    print(\"Unable to decode payload using any method.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDCVbL350y1N",
        "outputId": "2e9bd61b-beab-4be6-8a95-76b44d01ad6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Befor Decoded payload: \\u0053\\u0045\\u004C\\u0045\\u0043\\u0054\\u0020\\u002A\\u0020\\u0046\\u0052\\u004F\\u004D\\u0020\\u0075\\u0073\\u0065\\u0072\\u0073\\u0020\\u0057\\u0048\\u0045\\u0052\\u0045\\u0020\\u0075\\u0073\\u0065\\u0072\\u006E\\u0061\\u006D\\u0065\\u003D\\u0027\\u006A\\u006F\\u0068\\u006E\\u0027\\u003B\n",
            "After Decoded payload: SELECT * FROM users WHERE username='john';   :::   unicode_decode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Process"
      ],
      "metadata": {
        "id": "Vzcd-d2YMwML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_and_preprocess_data1(df_data):\n",
        "    print(f\"{TextStyle.BOLD}{TextStyle.BLUE}------------ Pre-Proccess ------------{TextStyle.RESET_ALL}\")\n",
        "\n",
        "    # ----------- Check for NaN Values ------------- #\n",
        "    print(\"Checking for NaN vallues ...\")\n",
        "    if df_data.isnull().values.any():\n",
        "        print(\"NaN values found in the dataset. Handling missing values...\")\n",
        "        # Handling missing values by imputing with mean (you can choose other methods as well)\n",
        "        df_data = df_data.fillna(df_data.mean())\n",
        "    df_data.replace([np.inf, -np.inf,np.nan,np.NAN],0, inplace=True)\n",
        "\n",
        "    if df_data.isnull().sum().sum() == 0 : # and np.isinf(df_data.values).sum() == 0 :\n",
        "        print('Done Handling missing values')\n",
        "\n",
        "\n",
        "    # ----------- lowercase + strip 'sentence' ------------- #\n",
        "    # Remove spaces in start and end\n",
        "    df_data['sentence'] = df_data['sentence'].str.strip()\n",
        "\n",
        "    # Convert to lowercase\n",
        "    df_data['sentence'] = df_data['sentence'].str.lower()\n",
        "\n",
        "\n",
        "    # ------------------------------------ Decode Sentence ------------------------------------ #\n",
        "    # Initialize an empty list to store the results\n",
        "    decoded_sentences = []\n",
        "    payload_types = []\n",
        "\n",
        "    for sentence in df_data['sentence']:\n",
        "        decoded_sentence, payload_type = decode_payload(sentence)\n",
        "        decoded_sentences.append(decoded_sentence)\n",
        "        payload_types.append(payload_type)\n",
        "\n",
        "    # Update the DataFrame with decoded sentences and payload types\n",
        "    #df_data['origin_sentence'] = df_data['sentence']\n",
        "    df_data['sentence'] = decoded_sentences\n",
        "    #df_data['payload_type'] = payload_types\n",
        "\n",
        "    # Print a sample of the DataFrame to check results\n",
        "    #print('After Decode :')\n",
        "    #print(df_data)\n",
        "\n",
        "\n",
        "    # ------------------------------------  separate target from predictors ------------------------------------ #\n",
        "    print(f\"{TextStyle.BOLD}{TextStyle.BLACK}------- separate target from predictors -------{TextStyle.RESET_ALL}\")\n",
        "\n",
        "    # Step 1 : define target column name and no. class in it\n",
        "    class_Col = 'attack_type'\n",
        "    n_classes = df_data[class_Col].nunique()      # no. classes/category in class_Col (attack_type)     n_classes = pd_frames['attack_type'].nunique()\n",
        "\n",
        "    # Step 2: define datatype for columns\n",
        "    df_data['len_payload'] = df_data['len_payload'].astype(int)\n",
        "\n",
        "    # Step 3: One-hot encode attack_type (not needed for discriminator)\n",
        "    #encoder = OneHotEncoder(sparse=False)\n",
        "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "    y = encoder.fit_transform(df[[class_Col]])\n",
        "    # encoded_attack_type_df = pd.DataFrame(encoded_attack_type, columns=encoder.get_feature_names_out([class_Col]))   # not in\n",
        "\n",
        "    X = df_data.drop(class_Col, axis=1)\n",
        "    #df_data = pd.concat([df_data.drop(class_Col, axis=1), encoded_attack_type_df], axis=1)\n",
        "\n",
        "    \"\"\"\n",
        "    # Step 4: Identify the feature columns (X) and the target columns (y)\n",
        "    # Assuming the target columns are all the one-hot encoded columns (with 'attack_type_' prefix)\n",
        "    # Automatically find the target columns based on the columns added during encoding\n",
        "    target_columns = [col for col in df_data.columns if col.startswith('attack_type_')]\n",
        "\n",
        "    # Features are all the other columns\n",
        "    feature_columns = [col for col in df_data.columns if col not in target_columns]\n",
        "\n",
        "    df_data1 = df_data[feature_columns]\n",
        "    y = df_data[target_columns]\n",
        "    X = df_data1\n",
        "    \"\"\"\n",
        "\n",
        "    # ------------------------------------ Apply encoding for categorical columns if any ------------------------------------ #\n",
        "\n",
        "\n",
        "\n",
        "    # ------------------------------------ train_test_split ------------------------------------ #\n",
        "    print(f\"{TextStyle.BOLD}{TextStyle.BLACK}------- Divide the dataset into training (70%) and testing (30%) -------{TextStyle.RESET_ALL}\")\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    print(\"Training data:\\n\")\n",
        "    print('X_train head: ', X_train.head , '\\n')\n",
        "    print('y_train head: ', y_train.head, '\\n')\n",
        "    print(f\"Training rows (70% of Dataset)\", \"X_train shape: \" , X_train.shape , \" -- y_train shape: \", y_train.shape , '\\n')\n",
        "    print(f\"Testing rows (30% of Dataset)\", \"X_test shape: \" , X_test.shape , \" -- y_test shape: \", y_test.shape , '\\n')\n",
        "\n",
        "    X_train = X_train.reset_index(drop=True)\n",
        "    X_test  = X_test.reset_index(drop=True)\n",
        "    y_train = y_train.reset_index(drop=True)\n",
        "    y_test  = y_test.reset_index(drop=True)\n",
        "\n",
        "    origin_x_train = X_train\n",
        "    origin_x_test = X_test\n",
        "\n",
        "\n",
        "\n",
        "    # ------------------------------------ Tokenization ------------------------------------ #\n",
        "\n",
        "\n",
        "\n",
        "    # ------------------------------------ TfidfVectorizer ------------------------------------ #\n",
        "    print(f\"{TextStyle.BOLD}{TextStyle.BLACK}------- TfidfVectorizer -------{TextStyle.RESET_ALL}\")\n",
        "    tfidf_vectorizer = TfidfVectorizer(dtype='float32')   # max_features=50\n",
        "\n",
        "\n",
        "    ## ==>>  X_train\n",
        "    X_tfidf = tfidf_vectorizer.fit_transform(X_train['sentence'])            # without Tokenization step\n",
        "    #X_tfidf = tfidf_vectorizer.fit_transform(df['decoded_sentence']).toarray()\n",
        "    X_tfidf_selected_features = tfidf_vectorizer.get_feature_names_out()\n",
        "    df_tfidf_x_train = pd.DataFrame(X_tfidf.toarray(), columns=X_tfidf_selected_features)\n",
        "\n",
        "    # Concatenate TF-IDF features with the original data excluding the sentence column\n",
        "    x_train_data = pd.concat([ X_train.drop(columns=['sentence'], inplace=True) , df_tfidf_x_train], axis=1)\n",
        "\n",
        "\n",
        "    ## ==>>  X_test\n",
        "    X_test_tfidf_values = tfidf_vectorizer.transform(X_test['sentence'])      # without Tokenization step\n",
        "    X_test_tfidf_selected_features = tfidf_vectorizer.get_feature_names_out()\n",
        "    df_tfidf_x_test = pd.DataFrame(X_test_tfidf_values.toarray(), columns=X_test_tfidf_selected_features)\n",
        "\n",
        "    # Concatenate TF-IDF features with the original data excluding the sentence column\n",
        "    x_test_data = pd.concat([ X_test.drop(columns=['sentence'], inplace=True)  , df_tfidf_x_test], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # ------------------------------------ MinMaxScaler ------------------------------------ #\n",
        "    print(f\"{TextStyle.BOLD}{TextStyle.BLACK}------- Scaling Features using 'MinMaxScaler' -------{TextStyle.RESET_ALL}\")\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    X_train_scaled = scaler.fit_transform(x_train_data)     #, axis=1)\n",
        "    X_test_scaled = scaler.transform(x_test_data)           #, axis=1)\n",
        "\n",
        "    # Convert the scaled numerical features back to DataFrames\n",
        "    x_train_data = pd.DataFrame(X_train_scaled, columns=x_train_data.columns)     #X_train_scaled_df\n",
        "    x_test_data = pd.DataFrame(X_test_scaled, columns=x_test_data.columns)        #X_test_scaled_df\n",
        "\n",
        "\n",
        "\n",
        "    # ------------------------------------ PCA for feature selection ------------------------------------ #\n",
        "    print(f\"{TextStyle.BOLD}{TextStyle.BLACK}------- PCA for feature selection -------{TextStyle.RESET_ALL}\")\n",
        "\n",
        "    n_components = 0.90   #0.95\n",
        "    pca = PCA(n_components=n_components, random_state=453)\n",
        "    #print('pca: ' , pca)\n",
        "\n",
        "\n",
        "    ## ------>> X_train << ------ ##\n",
        "    print('pca x_train data')\n",
        "    # Fit & Transform PCA on the training data\n",
        "    X_train_pca = pca.fit_transform(x_train_data)\n",
        "\n",
        "    # Convert PCA results back to DataFrames and concatenate with the original non-sentence columns\n",
        "    # Generate new feature names for PCA components\n",
        "    train_pca_feature_names = [f'pca_{i+1}' for i in range(X_train_pca.shape[1])]\n",
        "    X_train_pca_df = pd.DataFrame(data=X_train_pca, columns=train_pca_feature_names)      # Create a DataFrame with the PCA-transformed data\n",
        "    x_train_data = X_train_pca_df\n",
        "    print('end x_train_data')\n",
        "\n",
        "\n",
        "    ## ------>> X_test << ------ ##\n",
        "    print('pca x_test data')\n",
        "    X_test_pca = pca.transform(x_test_data)\n",
        "    test_pca_feature_names = [f'pca_{i+1}' for i in range(X_test_pca.shape[1])]\n",
        "    X_test_pca_df = pd.DataFrame(data=X_test_pca, columns=test_pca_feature_names)\n",
        "    x_test_data = X_test_pca_df\n",
        "    print('end x_test_data')\n",
        "\n",
        "\n",
        "\n",
        "    # variance ratio : show how much information (variance) can be attributed to each of the principal components.\n",
        "    # Calculate explained variance ratio and cumulative variance\n",
        "    explained_variance_ratio = pca.explained_variance_ratio_\n",
        "    cumulative_variance      = np.cumsum(explained_variance_ratio)    # Calculates the cumulative explained variance ratio for each component.\n",
        "    #print('explained_variance_ratio: ', explained_variance_ratio)\n",
        "    #print('cumulative_variance: ', cumulative_variance)\n",
        "\n",
        "\n",
        "    # Plot component variance and cumulative variance\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    colors_list = ['Red','Orange', 'Blue', 'Purple','Green','Pink','Gray','Tan','Lime','Cyan']\n",
        "\n",
        "    # Plot component variance with percentages\n",
        "    plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio * 100, label='Component Variance')\n",
        "    plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance * 100, marker='o', color='r', label='Cumulative Variance')\n",
        "\n",
        "    plt.title('Variance Explained by Principal Components\\n Dataset ')\n",
        "    plt.xlabel('Principal Component')\n",
        "    plt.ylabel('Percentage of Variance Explained (%)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    # Combine the PCA-transformed features with the target variable\n",
        "    print('pca concat')\n",
        "    x_train_data = pd.concat([X_train_pca_df, y_train], axis=1)\n",
        "    print('pca concat - end x_train_data')\n",
        "    x_test_data  = pd.concat([X_test_pca_df, y_test], axis=1)\n",
        "    print('pca concat - end x_test_data')\n",
        "    \"\"\"\n",
        "\n",
        "    #print('x_train_data head', x_train_data.head)\n",
        "    #print('X_train_pca_df shape: ', x_train_data.shape)\n",
        "    #print('x_test_data shape: ', x_test_data.shape)\n",
        "\n",
        "\n",
        "    return n_classes, x_train_data, x_test_data, y_train, y_test, origin_x_train, origin_x_test , y_datatype\n",
        "\n"
      ],
      "metadata": {
        "id": "f9eJjhiHN3cB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Code"
      ],
      "metadata": {
        "id": "ahnuV-3NM5le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------> Read Data of CSV Files <--------------------------- #\n",
        "dataset_directory = \"/content/datasets\"   #files_path\n",
        "percent = 100\n",
        "df = read_csv_files(dataset_directory,percent)\n",
        "print('len data : ' , len(df))\n",
        "\n",
        "class_Col = 'attack_type'\n",
        "min_rows_per_class = 2000  #50000\n",
        "origin_data = df\n",
        "\n",
        "\n",
        "# ---------------------------> Pre-Process <--------------------------- #\n",
        "load_and_preprocess_data1(df)"
      ],
      "metadata": {
        "id": "td--UZ_pM8lb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}